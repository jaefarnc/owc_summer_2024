{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a4cc9fa4-bf41-49c4-86bf-e19ea684a789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "base = \"ivory\"\n",
    "df = pd.read_csv(f'{base}/{base}_feature_engineered.csv')\n",
    "# df = pd.read_csv(f'{base}/{base}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c46f9729-04c1-4dd1-a222-362eeb269798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the new list of dictionaries\n",
    "import ast\n",
    "new_list = []\n",
    "\n",
    "\n",
    "\n",
    "# Iterate through each row in the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    username = row['username']\n",
    "    #join_date = row['join_date']\n",
    "    tweets = ast.literal_eval(row['tweets'])  # Convert string representation of list to an actual list\n",
    "    replies = ast.literal_eval(row['replies'])\n",
    "    for tweet in tweets:\n",
    "        tweet_link = tweet['tweet_link']\n",
    "        tweet_content = tweet['tweet_content']\n",
    "        new_list.append({\n",
    "            'tweet_link': tweet_link,\n",
    "            'username': username,\n",
    "            'tweet_content': tweet_content\n",
    "        })\n",
    "\n",
    "    for tweet in replies:\n",
    "        tweet_link = tweet['tweet_link']\n",
    "        tweet_content = tweet['tweet_content']\n",
    "        new_list.append({\n",
    "            'tweet_link': tweet_link,\n",
    "            'username': username,\n",
    "            'tweet_content': tweet_content\n",
    "        })\n",
    "\n",
    "\n",
    "# Now, new_list contains the transformed data\n",
    "#print(new_list)\n",
    "\n",
    "# If you want to save this list to a new CSV file:\n",
    "new_df = pd.DataFrame(new_list)\n",
    "new_df = new_df.dropna(axis = 0)\n",
    "new_df.to_csv(f'{base}/{base}_tweets.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "37f8062a-a627-4c1f-9dbf-53a91ff1c325",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to script WhiteBoard.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4e46f046-c5c2-42a6-bd91-ed952e370433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4b2a238c-0a1d-44e1-9c8f-9a8a363f7240",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{base}/{base}_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "58342de6-310d-4289-80fa-7efed4140f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125024\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "047a08cc-9f16-4f12-a085-a72fe08fae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"rhinohorn\"\n",
    "df = pd.read_csv(f'{base}/{base}_filtered_usercount.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "31ba5c5f-0b41-4963-b078-2f01a5c6d1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "977\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bd0d2b9f-b566-4f41-9ec7-62b78d478f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook Classification.ipynb to script\n",
      "[NbConvertApp] Writing 2514 bytes to classification_ivory.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script Classification.ipynb --output classification_ivory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b08cb55-0563-447d-aa30-2ad055157403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>handle</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>replies</th>\n",
       "      <th>tweet_count</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>username</th>\n",
       "      <th>tweets</th>\n",
       "      <th>join_date</th>\n",
       "      <th>following_count</th>\n",
       "      <th>...</th>\n",
       "      <th>post_freq</th>\n",
       "      <th>time_series</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>std_dev</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>25th_percentile</th>\n",
       "      <th>75th_percentile</th>\n",
       "      <th>num_scraped_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@invertposting</td>\n",
       "      <td>83</td>\n",
       "      <td>[{'tweet_link': '/invertposting/status/1794029...</td>\n",
       "      <td>1109.0</td>\n",
       "      <td>535</td>\n",
       "      <td>InvertebratePosting</td>\n",
       "      <td>[{'tweet_link': '/invertposting/status/1762851...</td>\n",
       "      <td>2:25 AM - 28 Feb 2024</td>\n",
       "      <td>179</td>\n",
       "      <td>...</td>\n",
       "      <td>1109.000000</td>\n",
       "      <td>[(1709078400, 2)]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@etonahatskelar</td>\n",
       "      <td>139</td>\n",
       "      <td>[]</td>\n",
       "      <td>49985.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Steam Mop Sale</td>\n",
       "      <td>[{'tweet_link': '/etonahatskelar/status/137845...</td>\n",
       "      <td>1:07 PM - 26 Sep 2011</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>925.648148</td>\n",
       "      <td>[(1321660800, 200)]</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>@AndyVermaut</td>\n",
       "      <td>31,846</td>\n",
       "      <td>[]</td>\n",
       "      <td>2646914.0</td>\n",
       "      <td>2,013</td>\n",
       "      <td>Andy Vermaut</td>\n",
       "      <td>[{'tweet_link': '/AndyVermaut/status/179434245...</td>\n",
       "      <td>4:39 PM - 17 Apr 2011</td>\n",
       "      <td>34,168</td>\n",
       "      <td>...</td>\n",
       "      <td>552.937957</td>\n",
       "      <td>[(1715817600, 2), (1715904000, 46), (171599040...</td>\n",
       "      <td>19.6</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.169106</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>8.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>@heartwhole24</td>\n",
       "      <td>1,163</td>\n",
       "      <td>[{'tweet_link': '/heartwhole24/status/17938064...</td>\n",
       "      <td>53146.0</td>\n",
       "      <td>129,682</td>\n",
       "      <td>TallysMum ðŸŒ¼ðŸŒ³ðŸª»ðŸ’•</td>\n",
       "      <td>[{'tweet_link': '/heartwhole24/status/17323651...</td>\n",
       "      <td>9:05 PM - 8 Aug 2023</td>\n",
       "      <td>1,603</td>\n",
       "      <td>...</td>\n",
       "      <td>442.883333</td>\n",
       "      <td>[(1701820800, 2)]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@EMaxwell56</td>\n",
       "      <td>327</td>\n",
       "      <td>[{'tweet_link': '/EMaxwell56/status/1793709763...</td>\n",
       "      <td>15335.0</td>\n",
       "      <td>5,946</td>\n",
       "      <td>EdMaxwell56</td>\n",
       "      <td>[{'tweet_link': '/EMaxwell56/status/1600948548...</td>\n",
       "      <td>3:50 AM - 3 Nov 2022</td>\n",
       "      <td>313</td>\n",
       "      <td>...</td>\n",
       "      <td>438.142857</td>\n",
       "      <td>[(1670457600, 2)]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           handle followers_count  \\\n",
       "0           0   @invertposting              83   \n",
       "1           1  @etonahatskelar             139   \n",
       "2           2     @AndyVermaut          31,846   \n",
       "3           3    @heartwhole24           1,163   \n",
       "4           4      @EMaxwell56             327   \n",
       "\n",
       "                                             replies  tweet_count likes_count  \\\n",
       "0  [{'tweet_link': '/invertposting/status/1794029...       1109.0         535   \n",
       "1                                                 []      49985.0           0   \n",
       "2                                                 []    2646914.0       2,013   \n",
       "3  [{'tweet_link': '/heartwhole24/status/17938064...      53146.0     129,682   \n",
       "4  [{'tweet_link': '/EMaxwell56/status/1793709763...      15335.0       5,946   \n",
       "\n",
       "              username                                             tweets  \\\n",
       "0  InvertebratePosting  [{'tweet_link': '/invertposting/status/1762851...   \n",
       "1       Steam Mop Sale  [{'tweet_link': '/etonahatskelar/status/137845...   \n",
       "2         Andy Vermaut  [{'tweet_link': '/AndyVermaut/status/179434245...   \n",
       "3       TallysMum ðŸŒ¼ðŸŒ³ðŸª»ðŸ’•  [{'tweet_link': '/heartwhole24/status/17323651...   \n",
       "4          EdMaxwell56  [{'tweet_link': '/EMaxwell56/status/1600948548...   \n",
       "\n",
       "               join_date following_count  ...    post_freq  \\\n",
       "0  2:25 AM - 28 Feb 2024             179  ...  1109.000000   \n",
       "1  1:07 PM - 26 Sep 2011              13  ...   925.648148   \n",
       "2  4:39 PM - 17 Apr 2011          34,168  ...   552.937957   \n",
       "3   9:05 PM - 8 Aug 2023           1,603  ...   442.883333   \n",
       "4   3:50 AM - 3 Nov 2022             313  ...   438.142857   \n",
       "\n",
       "                                         time_series   mean median    std_dev  \\\n",
       "0                                  [(1709078400, 2)]    2.0    2.0   0.000000   \n",
       "1                                [(1321660800, 200)]  200.0  200.0   0.000000   \n",
       "2  [(1715817600, 2), (1715904000, 46), (171599040...   19.6   14.0  16.169106   \n",
       "3                                  [(1701820800, 2)]    2.0    2.0   0.000000   \n",
       "4                                  [(1670457600, 2)]    2.0    2.0   0.000000   \n",
       "\n",
       "   min  max 25th_percentile  75th_percentile  num_scraped_tweets  \n",
       "0    2    2             2.0              2.0                   2  \n",
       "1  200  200           200.0            200.0                 200  \n",
       "2    2   54             8.5             20.0                 196  \n",
       "3    2    2             2.0              2.0                   2  \n",
       "4    2    2             2.0              2.0                   2  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "base = \"pangolin\"\n",
    "df = pd.read_csv(f'{base}/{base}_feature_engineered.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ab06264-c4cc-4091-b4b4-bd2c4ab0205a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(f'{base}/{base}_feature_engineered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3cfb35d3-e31c-433a-ba92-b429fe5dad79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "def stdify(row):\n",
    "    time_series = row['time_series']\n",
    "    temp = ast.literal_eval(time_series)\n",
    "    total_time = 0.0\n",
    "    total_count=0\n",
    "    weighted_sum_of_time_and_count=0.0\n",
    "    for point in temp:\n",
    "        total_time += point[0]\n",
    "        total_count += point[1]\n",
    "        weighted_sum_of_time_and_count += point[0]* point[0]\n",
    "    # Calculate mean (weighted average)\n",
    "    mean = weighted_sum_of_time_and_count / total_count\n",
    "\n",
    "    # Calculate squared deviations from the mean\n",
    "    squared_deviations = [((point[0] - mean) * point[1])**2 for point in temp]\n",
    "\n",
    "    # Calculate variance (average of squared deviations)\n",
    "    variance = sum(squared_deviations) / total_count\n",
    "\n",
    "    # Calculate standard deviation (square root of variance)\n",
    "    std = variance**0.5\n",
    "    return std\n",
    "        \n",
    "df['std_dev'] = df.apply(stdify,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad2cf6c7-1e67-45ae-9eb3-13ce64ab6723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac18fe3a-fe6a-459c-a31b-e9c5ef86cc0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
